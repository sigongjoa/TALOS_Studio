## 🎬 프레임 정보량 및 의미 임베딩 모델 요약

---

### 🎯 개요

한 컷의 이미지를 단순한 픽셀 데이터가 아닌 **정보량(Information Density)** 으로 해석하고, 이를 딥러닝으로 근사화하기 위한 구조를 정의한다. 핵심은 물리적(고주파/저주파) 정보 + 시각적(Conv) 정보 + 의미적(Embedding) 정보를 통합하는 것이다.

---

### 🧩 1️⃣ 프레임 정보량 계층 구조

한 프레임은 다음의 네 가지 정보 레이어로 분해된다.

| 계층                 | 설명                 | 추출 방법                                 | 벡터 형태                      |
| :----------------- | :----------------- | :------------------------------------ | :------------------------- |
| **Geometry Layer** | 선, 곡선, 구조적 형태      | FFT 고주파 추출 + Curve Fitting            | [x, y, θ, κ, w, c] × N     |
| **Color Layer**    | 색상, 명암, 채도 분포      | 저주파 분석 + Conv Feature                 | [L, a, b, variance, light] |
| **Material Layer** | 질감, 반사율, roughness | CNN feature / intrinsic decomposition | [n_x, n_y, n_z, r, s]      |
| **Semantic Layer** | 의미, 감정, 맥락         | CLIP / BLIP / LLaVA                   | [v₁, v₂, …, v_d]           |

이 네 가지 레이어는 통합되어 하나의 **프레임 정보 벡터 (Information Vector)** 로 구성된다.

[ F = v_geo ⊕ v_color ⊕ v_mat ⊕ v_sem ]

---

### ⚙️ 2️⃣ 주파수 기반 정보량 분석

1. **Fourier 변환을 통해 이미지 분해**

   * 저주파(면, 색상, 구도)
   * 고주파(윤곽선, 질감, 디테일)

2. **고주파 에너지 계산**
   한 컷의 복잡도를 주파수 에너지로 정량화:

   [ E_high = ∑ |I_high(x, y)|² ]

3. **정보량 모델 통합식**
   [ I_frame = αE_high + βH(F_color) + γVar(F_structure) ]

---

### 🧠 3️⃣ 의미적 임베딩 (Semantic Embedding)

**의미적 임베딩**은 이미지의 감정, 맥락, 상징을 언어-시각 공동 공간으로 변환한 벡터이다.

* 모델: CLIP, BLIP, SigLIP, LLaVA
* 수식:
  [ z_img = f_image(x),\quad z_text = f_text(y) ]
  [ L = -\log \frac{exp(sim(z_img, z_text)/τ)}{∑_j exp(sim(z_img, z_text_j)/τ)} ]

이로써 **이미지 ↔ 언어 의미**가 정렬된 잠재 공간(latent space)이 만들어진다.

CLIP 벡터는 다음 의미를 내포한다:

* 사물 및 인물 (object-level)
* 감정 / 분위기 (affective-level)
* 행동 / 장면 맥락 (contextual-level)

결과적으로 프레임의 **의미 정보량**은 다음으로 표현된다:

[ I_semantic = -∑ p(v_i) log p(v_i) ]

---

### 🧩 4️⃣ 전체 파이프라인 요약

**입력:** 프레임 이미지 (I)

➡ **FFT 분해:** ( I → I_low, I_high )

➡ **CNN 특징 추출:** ( F = Conv(I_low, I_high) )

➡ **Feature Pooling:** ( v_frame = GAP(F) )

➡ **CLIP 의미 임베딩:** ( v_sem = f_{CLIP}(I) )

➡ **최종 정보 벡터:** ( V = [v_geo ⊕ v_color ⊕ v_mat ⊕ v_sem] )

➡ **정보량 계산:** ( I_frame = H(V) )

---

### 🔮 5️⃣ 응용

| 응용 분야              | 설명                                   |
| :----------------- | :------------------------------------ |
| **정보량 기반 복잡도 평가**  | 한 컷의 엔트로피를 수치화하여 복잡도, 연출 강도 평가       |
| **리듬 / 타이밍 차트 생성** | 시간 축 정보량 변화를 이용해 감정의 리듬 자동 생성        |
| **AI 원화 품질 제어**    | 프레임별 정보량을 기준으로 디테일 / 단순화 수준 자동 제어    |
| **LLM 피드백 루프**     | CLIP 의미 벡터 → 텍스트 설명 → LLM 해석 및 연출 보정 |

---

### 📘 결론

이 시스템은 **한 프레임의 시각적·의미적 정보량을 정량화하고**, 이를 통해 AI가 “그림의 복잡도와 감정의 밀도”를 이해하게 만드는 프레임워크다.
즉, AI가 단순히 ‘그리는 법’을 배우는 것이 아니라 —
**‘얼마만큼 복잡하게, 어떤 의미로 그려야 하는가’를 학습하는 구조**다.
